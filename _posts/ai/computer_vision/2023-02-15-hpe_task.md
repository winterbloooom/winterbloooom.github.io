---
title:  "[HPE] Human Pose Estimation Task 소개: Introduction, Application, Challenges"
excerpt: "Human Pose Estimation task introduction, applications, and challenges"
categories:
  - AI
  - Computer Vision
tags:
  - Deep Learning
  - Computer Vision
  - Human Pose Estimation
last_modified_at: 2023-02-15
teaser: "/assets/images/teaser/teaser_hpe.jpg"
---

{% include inserted_box.html text="HPE 시리즈는 현재 필자가 연구(공부)하는 주제로, 이와 관련된 이론 및 논문들을 소개할 예정입니다." %}



<figure>
<img src="https://user-images.githubusercontent.com/69252153/218929973-7ad98a62-8830-4265-a0bf-d672f5712eba.png">
<figcaption>Kaiming He et al, "Mask R-CNN", ICCV 2017</figcaption>
</figure>


<figure>
<img src="https://user-images.githubusercontent.com/69252153/218930869-05532411-3169-41a4-bb1f-b0c8f5274d67.png">
<figcaption>Zhe Cao et al, "Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields", CVPR 2017</figcaption>
</figure>

# Introduction of HPE Task

<span style="background-color: #C5D3F6">Human Pose Estimation</span>은 말 그대로 사람의 자세를 추정하는 일이다. 축약해 HPE라고 부른다.

다른 말로는 <span style="background-color: #C5D3F6">Keypoint Detection</span>이라고도 한다. 자세를 추정할 때 각 관절(joint, part) 위치를 찾는데, 이때 이 joint나 part를 keypoint(키포인트)라고 하기 때문이다. 위 사진들은 각 관절을 선으로 연결해놓았지만, 실질적으로 이 task를 수행할 때는 관절 위치만 찾으면 된다.

<div id="def-box">
<div class="def-title">자주 사용하는 용어 정리</div>
<div markdown="1" style="line-height: 1.6rem">

* Human Pose Estimation (abbr. 'HPE' 혹은 'PE') : 사람의 자세를 추정하는 일을 말한다.
* Keypoint (abbr. 'kpt') : 키포인트. 관절(joint)을 말한다.
* Instance : 인스턴스. 각 사람 하나를 말한다. 자세를 추정할 때 각 사람별로 정확한 관절들을 찾아내야 한다.

</div>
</div>

HPE는 <span style="background-color: #C5D3F6">주어진 사진 혹은 비디오에서 그 안에 있는 모든 사람들의 관절(e.g. 팔꿈치, 손목 등)의 위치를 정확히 탐지한다.</span>

- - -

# Application

HPE는 사람의 이해(human understanding)에 중요한 역할을 한다. HPE 자체도 연구 분야이지만, HPE를 활용한 다른 task나 활용 분야가 매우 많다.

대표적으로 <span style="background-color: #C5D3F6">행동 분석(action analysis), 보행자 추적(pedestrain tracking) 및 re-identification, Human-Computer Interaction(HCI), 게임, 의료 활용, 스포츠 분석, 애니메이션 및 CGI, VR 및 AR 등</span>에 사용된다. 및에선 구체적 몇 가지 사례를 들어본다.

## Animation, CGI, VR & AR

오래된 애니메이션 영화를 떠올려보면, 영화를 제작하기 위해서는 프레임 단위로 직접 그림을 그려 영상을 완성했다. 이는 비용도 많이 들고 시간도 많이 소모된다. 

그러나 HPE은 해당 작업을 크게 바꿔놓았다. 사람(performer)의 움직임을 캐릭터로 전이(transfer)시켜서 애니메이션을 만드는 것이다. 이는 가상현실(Virtual Reality)나 증강현실(Augmented Reality)에도 유용하여, HPE에서 얻은 골격(skeleton) 정보로부터 3D 애니메이션을 만들어낼 수도 있다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/218938535-71535484-f47f-46cd-bb43-9d138796beb0.png" width="50%">
<figcaption>Dong-Hyun Hwang et al, "Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning", WACV 2020</figcaption>
</figure>

영화 및 드라마 산업에서 CGI(Computer Generated Imagery, 컴퓨터 생성 이미지)는 매우 자주 쓰이지만 굉장히 비싼 작업이다. 마블(Marvel) 사의 어벤저스(Avergers) 시리즈만 보아도 거의 대부분이 CG라 해도 과언이 아니다. 제작 과정을 담은 비디오를 보면, 배우들이 특별 수트나 마스크를 작용해 움직임을 포착한다. HPE를 더 이용하면 2D에서도 키포인트를 추출해 3D 렌더링을 시킬 수도 있다.

## Sports

스포츠에서 경기를 분석할 때 주로 사진이나 비디오를 찍어 천천히 돌려보면서 자세, 전략 등을 분석하곤 한다. 그러나 이를 HPE와 결합하면 자동적으로 자세와 움직임 분석이 가능하고 더 나아가 적당한 개선 방향도 제시할 수 있다. 상대 선수의 강점과 약점을 분석하기도 용이하다.

시범자(instructor)와 학습자(learner)의 자세를 비교해 어딜 어떻게 교정해야 하는지도 알 수 있으며, 범용적 어플리케이션으로 만든다면 전문 선수나 트레이너가 아니더라도 분석을 할 수 있고 분석을 받을 수 있다.

골프, 테니스, 요가 등 다양한 운동 종목에 이미 적용이 시작되고 있다. 아래 GIF는 AI 요가 앱인 Zenia의 예이다. 카메라를 통해 사용자의 자세를 탐지하고, 정확한 자세로 교정해준다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/218943469-355cea85-1d0e-483d-be85-aa761e59bd49.gif" width="60%">
<figcaption>Zenia Instagram</figcaption>
</figure>

아래는 골프 자세 교정을 위한 논문의 예시이다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/218949733-3ef35379-8bbd-4241-a11c-142d2e00aa83.png" width="70%">
<figcaption>"Accurate and efficient 3D human pose estimation algorithm using single depth images for pose analysis in golf", CVPR 2017</figcaption>
</figure>

이러한 분석은 전문 선수와 일반인의 스포츠 중 부상을 방지하는 효과를 가져올 수 있다.

## Human-Computer Interaction(HCI)

전통적 HCI 기술은 직접 만질 수 있는 기기나 인터페이스를 통해 이루어졌다. 예를 들자면 마우스나 키보드, 터치스크린 등이다. 그러나 HPE를 적용한다면 접촉 없이도 카메라를 통해 조종이 가능해진다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/218944786-7ef7480c-1578-4f79-a825-b6fffe392e4e.png" width="70%">
<figcaption>Spider-Man: Far from Home(2019)</figcaption>
</figure>

아이언맨이나 스파이더맨 등의 영화를 보면 허공에서 손을 움직여 기기를 작동시키는 등의 일을 한다. 이 작업은 사람의 손가락 움직임을 탐지하는 것에서 시작한다.

이는 영화 속 기술만은 아니다. 예술과 게임, 가상현실에 이미 적용이 되고 있다. 아래 사진과 같이 Microsoft Kinect 를 활용해 게임을 할 수 있다. 상호작용하는 게임 경험을 제공하는 것이다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/218946195-eb97276c-05ca-434e-82d2-70d265e51706.png" width="70%">
<figcaption>yahoo finance, "The rise and fall of Kinect: Why Microsoft gave up on its most promising product"</figcaption>
</figure>

## Medical & Clinical Applications

환자나 노인의 경우 보호자가 항시 주시하고 있을 순 없는데, 이때 HPE 기술을 활용해 모니터링을 실시할 수 있다. 혹은 재활 치료에도 도움이 될 수 있는데, 이는 위에서 소개한 스포츠 코칭과 상당히 유사하게 작동한다.

혹은 아이의 움직임 분석에 사용할 수도 있다. 아이가 근육, 관절, 신경계 등 신체 문제를 가지고 있을 때 움직임에 이상을 보인다. 이러한 아이의 성장 행동, 물리적 발달 과정을 분석할 수 있다. 의료 지식이 없는 부모가 해당 기술을 통해 아이의 움직임으로부터 미묘한 이상(anomalies)을 알아내 의사에게 적절한 치료를 받도록 한다. 

## 그 외

위에서 열거한 예시는 일부일 뿐이다.

자율주행, ADAS(advanced driver assistance systems)에서도 HPE는 유용하여, 차량에 탑승한 운전자나 동승자의 움직임을 알 수도 있고, 보행자의 움직임을 추적할 수도 있다.

스마트 관제 시스템(surveillance system)은 노인 모니터링을 통해 위험한 활동에 경고를 해주거나, 건설 인부들의 위험 행동을 모니터링 할 수 있다.

전체 자세 뿐만 아니라 손이나 얼굴 등 세부 포즈 추정 분야도 존재한다. 일례로 팔과 손가락 탐지를 통해 수화를 분석할 수 있다.

- - -

# Challenges

## Occlusion & Truncation

여타 컴퓨터 비전 task에서 공통적으로 골머리를 앓는 것이 <span style="background-color: #C5D3F6">occlusion, 즉 가려짐 문제</span>이다. 3차원 정보가 없을 땐 오직 2차원 평면에서만 추론을 수행해야 하는데, 한 물체가 다른 물체에 가려져 있으면 가려진 부분은 추론이 힘들기 때문이다.

HPE 역시 마찬가지다. 이미지에서 두 사람의 일부가 겹쳐있다고 생각해보자. A의 손목이 B에 의해 가려졌다면 A의 손목은 이미지에서 보이지 않으므로 정확한 위치를 찾는 것이 힘들어진다. 즉 Reconstruction ambiguity를 발생시킨다. 특히 이 문제는 사람이 많은 상황(crowd)에서 빈번하고 심각하게 발생한다.

아래 사진처럼 앞 사람이 뒷 사람의 몸통을 거의 다 가리고 있을 때 뒷 사람의 정확한 관절 위치를 예측하기란 매우 어렵다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219265164-aa3c0d83-4cd2-4544-9dde-389593cd5de8.jpg" width="50%">
<figcaption>Image from CrowdPose dataset</figcaption>
</figure>

가려짐 뿐만 아니라 잘림(truncation)도 문제다. 상반신만 나온 사진에서 억지로 발목을 찾으려 하면 문제가 된다.

## Multiple people, Crowd Scenes

<span style="background-color: #C5D3F6">이미지 내에는 여러 명의 사람이 존재하며, 정확히 몇 명이 존재하는지도 알지 못한다.</span> 그럼에도 그들 모두를 탐지해야 한다. 뿐만 아니라 그들의 크기와 위치도 제각각이다.

현존하는 모델들은 매우 좋은 성능을 보여주고는 있으나, 군중(crowd) 상황에서 성능이 급격하게 떨어진다. 다수의 사람이 참여하는 게임 혹은 스포츠 분석에서는 사람의 수에 관계 없이 강인상 성능을 가지는 모델이 필요하다. 하여 최근 논문들은 군중 상황을 담은 데이터셋(e.g. CrowdPose dataset)을 통해 성능 검증을 추가적으로 수행하고 있기도 하다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219264363-5c44f265-3a28-479b-9921-ccc2158938fd.jpg" width="60%">
<figcaption>Image from CrowdPose dataset</figcaption>
</figure>

## Interactions between people

사진 속 사람들은 물체 혹은 다른 사람들과 상호작용을 한다. 악수나 포옹, 운동 등 우리 일상을 상기해보자. 이러한 상호작용으로 인해 사진에서 보았을 땐 사람 간의 접촉이나 가려짐(occlusion)이 발생한다. HPE에서 특히 문제가 되는 가려짐 역시 사람이 많거나 가까운 상호작용이 발생할 때 빈번하게 나타난다(mutual occlusion). <span style="background-color: #C5D3F6">사람 간의 상호작용</span>이 있는 사진은 공간적 추론을 매우 복잡하게 만든다. 각 사람의 신체 부위를 나누고 할당하기(Part association)가 어려우며, 연산 복잡도가 증가한다. 

## Runtime complexity

이미지 내 사람이 많은 것은 정확도에만 영향을 주는 것이 아니다. 특히 문제가 되는 부분은 연산 시간(inference time)이다.

<span style="background-color: #C5D3F6">연산 시간은 이미지 내 사람의 수에 비례해 증가한다.</span> 뒤에 이어질 포스팅에서 자세히 설명하겠지만, two-stage 방법들은 어떤 모델을 쓰든 추가적 단계가 필요한데 이 단계들이 사람 수에 따라 연산을 증가시킨다.

사람을 탐지하고 개별적 바운딩박스에서 HPE를 수행하는 Top-down methods는, 탐지 단계(detection)도 필요할 뿐더러 사람의 수만큼 HPE를 수행해야 한다. 만약 이미지 내 사람이 100명이면 100번 개별적 HPE를 수행해야 하는 것이다.

모든 관절들을 다 탐지한 뒤 개개인의 관절 주인을 찾아주는 Bottom-up methods는, 키포인트 간의 유사도 값을 계산하고 이를 매칭 알고리즘으로 그룹핑(grouping)해야 한다. 만약 이미지 내 사람이 100명이고 탐지된 관절 개수가 1,000개라면 각 1,000개를 100명에게 나눠주는(그룹핑) 작업이 필요한 것이다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219264852-cf2769cd-7a0b-4623-be6e-fdb87583fe43.png" width="90%">
<figcaption>Zheng, C. et al, "Deep learning-based human pose estimation: A survey," arXiv (2020)</figcaption>
</figure>

이러한 복잡성은 HPE를 <span style="background-color: #C5D3F6">실시간으로 작동하게 하는(realtime inference) 데 큰 걸림돌이 되고 있으며, 리소스가 제한된(resource-limited) 디바이스에서 수행이 힘든 이유</span>가 된다.

## Efficiency

앞 내용과 이어지는 주제다. HPE는 연산 비용이 높은 task이다. 그래서 추론 지연(inference delay)도 빈번하게 발생한다. 따라서 모바일 디바이스, 임베디드 디바이스로의 탑재가 힘들다. 그래서 정확도를 높이려는 시도 뿐만 아니라, 가볍고 효율적인 신경망을 디자인하려는 시도가 계속되고 있다.

## Wide diversity of human body

추론을 해야 하는 사진은 깔끔한 배경이 아닌 잔디밭, 교실, 집, 쇼핑몰 등 다양한 환경이 있을 수 있고, 흐린 날이나 비가 오는 날, 자외선이 심한 날, 인공 조명 아래 등 조명 조건(illumination conditions)도 다를 수 있다. 이미지 자체에 흐려짐(blur)가 발생하거나 초점이 사라질(defocus) 수도 있다. 이런 다양한 상황들은 HPE 뿐만 아니라 다른 컴퓨터 비전 task에서도 문제가 되는 부분이다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219263207-a2d39e03-4779-4128-a01f-059ce8821198.jpg" width="60%">
<figcaption>Image froom CrowdPose dataset</figcaption>
</figure>

뿐만 아니라 HPE에서 처리해야 하는 사람에겐 더 많은 어려움이 있다.

일단, 사진 내 <span style="background-color: #C5D3F6">사람은 다양한 의상을 입고 있다</span>. 예를 들어, 펑퍼짐한 의상이나 풍성한 치마일 경우 정확한 관절 위치를 찾기 힘들다.

또한 <span style="background-color: #C5D3F6">사람의 몸은 매우 큰 자유도(high degree of freedom)을 가지고 있어 변형 가능성이 매우 높다(high deformable)</span>. 쉽게 말해, 관절을 자유자재로 움직여 셀 수 없이 다양한 포즈를 가질 수 있단 의미이다. 리듬체조를 떠올려 보자. 사람이 어떻게 저렇게 몸을 만드나 싶을 정도로 기괴한 자세도 가능하다. 따라서 정해진 몇 가지 템플릿으로 추정하는 일은 불가하며, 그래서 추론 복잡성도 그에 따라 증가한단 의미다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219249548-839a5802-6891-425f-81bd-25f4f985d025.jpg" width="60%">
<figcaption>Image by Katie Bush from Unsplash</figcaption>
</figure>

## Biased dataset

신경망을 학습시키기 위해선 데이터셋이 필요하다. 물론 HPE를 위한 다양한 데이터셋이 존재하나, 데이터셋에도 HPE가 넘어야 할 산이 있다.

일단, 흔하지 않게 발생하는 자세가 잘 없다. 서 있거나 앉아 있는 일상적 상황이 대다수이고, 상공에서 낙하하는 자세나 복잡한 자세는 데이터셋에 많이 없다.

이런 <span style="background-color: #C5D3F6">편향된 데이터셋(biased dataset)은 불균형적 학습 문제(imbalanced learning problem)</span>를 야기한다. 그럼 모델은 희귀한 상황에 대한 대처를 학습하지 못하고, 실제 적용 시에 큰 에러가 발생할 수 있다.

3차원으로 가면 상황은 더 심각해진다. 단순한 annotation을 수행하면 되는 2차원과는 다르게, 정확한 공간 정보가 필요한 <span style="background-color: #C5D3F6">3차원 데이터셋을 만들기 위해서는 다양한 시점에서 본 카메라(multi-view cameras)나 신체 부작 센서들(IMU 등)을 갖춘 실험실 환경이 필요</span>하다. 따라서 야외 환경에 대한 3차원 데이터셋이 거의 전무하고 있다 해도 불완전하다. 불완전한 데이터셋으로 학습한 모델은 잘 작동하지 못하므로, 3차원 HPE의 실제 적용은 요원한 일이 된다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219263040-59f96942-b929-4168-bc88-7fb0cd2522e3.png" width="80%">
<figcaption>CMU Panoptic Studio</figcaption>
</figure>

물론 semi-supervised learning(준지도학습) 등을 활용하거나 합성 데이터셋(synthetic dataset)을 이용하는 방법도 존재는 하지만, 여전히 일정량의 데이터셋이 필요하거나 전이학습(transfer learning)이 제대로 이루어지지 않는 한계가 있다.

## 3D HPE

앞서 꼬집은 것처럼, 3차원 HPE는 데이터셋 자체도 불완전해 <span style="background-color: #C5D3F6">야외 환경에서 특히 작동이 힘들다</span>. 뿐만 아니라 추론해야 할 정보도 많아서 edge-device에서 실시간 추론이 잘 안되는 것도 문제다.

따라서 깊이(depth) 정보를 추가적으로 얻어 HPE에 사용하는 등 다양한 시도가 수행되고 있으며, 3D HPE를 빠르고 효율적으로 해내는 것도 추후의 과제다.

<figure>
<img src="https://user-images.githubusercontent.com/69252153/219263854-0946df1b-998e-4b1a-8f2d-961a643bea04.png" width="90%">
<figcaption>Xiao, Yabo, et al. "AdaptivePose++: A Powerful Single-Stage Network for Multi-Person Pose Regression." arXiv(2022)</figcaption>
</figure>

- - -

# References

<div id="inserted-box">
    <div class="notice-text"><p markdown="1">HPE 시리즈에서 사용하는 모든 레퍼런스는 한꺼번에 [[HPE] Human Pose Estimation References]({% link _posts/ai/computer_vision/2023-02-14-hpe_ref.md %})에 모아두었다.</p></div>
</div>

* <span style="background-color: #C5D3F6">[PETR(2022)]</span> Shi, Dahu, et al. "End-to-end multi-person pose estimation with transformers." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022.
* <span style="background-color: #C5D3F6">[SPM(2019)]</span> Nie, Xuecheng, et al. "Single-stage multi-person pose machines." *Proceedings of the IEEE/CVF international conference on computer vision*. 2019.
* <span style="background-color: #C5D3F6">[CMU-Pose(2017)]</span> Cao, Zhe, et al. "Realtime multi-person 2d pose estimation using part affinity fields." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2017.
* <span style="background-color: #C5D3F6">[HRNet(2019)]</span> Sun, Ke, et al. "Deep high-resolution representation learning for human pose estimation." *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*. 2019.
* <span style="background-color: #C5D3F6">[survey2020(1)]</span> Munea, Tewodros Legesse, et al. "The progress of human pose estimation: A survey and taxonomy of models applied in 2D human pose estimation." *IEEE Access* 8 (2020): 133330-133348.
* <span style="background-color: #C5D3F6">[survey(2022)]</span> Lan, Gongjin, et al. "Vision-Based Human Pose Estimation via Deep Learning: A Survey." *IEEE Transactions on Human-Machine Systems* (2022).
* <span style="background-color: #C5D3F6">[v7labs-HPE]</span> [A Comprehensive Guide to Human Pose Estimation](https://www.v7labs.com/blog/human-pose-estimation-guide)